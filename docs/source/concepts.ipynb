{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concepts\n",
    "\n",
    "## General idea\n",
    "\n",
    "We take following ideas from:\n",
    "* `Isolation Forest` - To identify outliers perform random splits in the attribute space. Anomalies will be isolated very soon thanks to it and we can easily identify them by checking average depth.\n",
    "* `Similarity Forest` - This was created with classification task in mind. It can work with any type of objects and is based on similarity between them. So having our dataset with 4 examples and 3 attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 4 2]\n",
      " [2 3 1]\n",
      " [3 2 4]\n",
      " [4 1 3]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(23)\n",
    "X = np.array([\n",
    "    [1, 4, 2],\n",
    "    [2, 3, 1],\n",
    "    [3, 2, 4],\n",
    "    [4, 1, 3],\n",
    "])\n",
    "print(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We at first select a pair of objects $O_{i}$ and $O_{j}$. In this case this is object 0 and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 4 2] [4 1 3]\n"
     ]
    }
   ],
   "source": [
    "i, j = 0, 3\n",
    "Oi, Oj = X[i], X[j]\n",
    "print(Oi, Oj)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Finally we perform a projection of every object $k$ based on similarity $S_{ki}$ and $S_{kj}$ defined as:\n",
    "\n",
    "$$\n",
    "    Projection(k) = S_{ki} - S_{kj}\n",
    "$$\n",
    "\n",
    "e.g we can define this projection w.r.t euclidean dot product as a similarity measure\n",
    "\n",
    "$$\n",
    "    Projection(k) = dot(O_{k},O_{i}) - dot(O_{k}, O_{j})\n",
    "$$\n",
    "\n",
    "In our example we obtain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot(X, Oi) =  [21 16 19 14]\n",
      "Dot(X, Oj) =  [14 14 26 26]\n",
      "Projection =  [  7   2  -7 -12]\n"
     ]
    }
   ],
   "source": [
    "dot_oxi = np.dot(X, Oi)\n",
    "dot_oxj = np.dot(X, Oj)\n",
    "print(\"Dot(X, Oi) = \", dot_oxi)\n",
    "print(\"Dot(X, Oj) = \", dot_oxj)\n",
    "print(\"Projection = \", dot_oxi - dot_oxj)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we perform everything as in the Isolation Forest algorithm. Every time a different $O_{i}$ and $O_{j}$ is selected we obtain different projection. The example may look very simple. However, this approach is quite powerful as object and this similarity functions can be literally of any type which was tested in our third inspiration.\n",
    "* `Random Similarity Forest` - here authors extended Similarity Forest to work with objects like graphs, distributions, sets etc. and moreover allowed using of mixed datasets. Imagine one column of your data is a graph and another is a set. You can easily use this algorithm by just defining some similarity measures between them.\n",
    "\n",
    "\n",
    "In `Generalized Isolation Forest (GIF)`we merge all this ideas and add some small tweaks to allow easily use any of the proposed solutions above.\n",
    "\n",
    "\n",
    "## Data object\n",
    "\n",
    "As said previously GIF can work with mixed datasetypes - one instance in a dataset can be represented by many modalities at the same type. Moreover you can assign as many distance functions to every modality as you want you can visualize it like this.\n",
    "\n",
    "![fishy](_static/dataset.png)\n",
    "\n",
    "Now:\n",
    "1. *F1* is a nominal feature you can use `Dice Coefficiant` for it.\n",
    "2. *F2* is a numerical vector that in general can be in $\\mathbb{R}^n$. You can use Euclidean, Manhattan, any p-norm or cosine similarity.\n",
    "3. *F3* Here we have distribution so you can use Kolmogorov-Smirnov distance, Information-divergence\n",
    "4. *F7* with graph you can go with Ipsen-Mikailov, Portrait etc.\n",
    "\n",
    "Some distances are computationally heavy and using them on entire data would be prohibitive that's why we introduce distance `precomputing` and `n_selected_objects` parameter that restrict number of necessary computations. We write about them later.\n",
    "\n",
    "So how to create this kind of dataset? We introduce `RISFData` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.set_printoptions(edgeitems=30, linewidth=100000, \n",
    "    formatter=dict(float=lambda x: \"%.3g\" % x))\n",
    "class Graph():\n",
    "    pass\n",
    "\n",
    "def jaccard_projection(x, y):\n",
    "    pass\n",
    "\n",
    "def euclidean_projection(x, y):\n",
    "    pass\n",
    "\n",
    "def cosine_projection(x, y):\n",
    "    pass\n",
    "\n",
    "def jaccard_distance(x, y):\n",
    "    pass\n",
    "\n",
    "def ipsen_mikailov(x, y):\n",
    "    pass\n",
    "\n",
    "def portrait(x, y):\n",
    "    pass\n",
    "\n",
    "class Tree():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rsif.rsif_data import RsifData\n",
    "from rsif.distance import TrainDistanceMixin, SelectiveDistance # We will explain them later\n",
    "data = RsifData()\n",
    "\n",
    "categorical_feature = np.array([[0], [2], [1]])\n",
    "distances_categorical = [SelectiveDistance(projection_func = jaccard_projection, min_n=1, max_n=1)]\n",
    "data.add_data(categorical_feature, distances_categorical)\n",
    "\n",
    "numerical_features = np.random.randn(3, 3) # vector in R^3\n",
    "distances_numerical = [SelectiveDistance(projection_func = euclidean_projection, min_n=1, max_n=3),\n",
    "                        SelectiveDistance(projection_func = cosine_projection, min_n=1, max_n=3)]\n",
    "data.add_data(numerical_features, distances_numerical)\n",
    "\n",
    "set_features = np.array([{10, 20, 30}, {20, 30}, {10, 20}])\n",
    "distances_set = [TrainDistanceMixin(distance = jaccard_distance)]\n",
    "data.add_data(set_features, distances_set)\n",
    "\n",
    "graph_features = np.array([Graph(), Graph(), Graph()]) # Graph is just a dummy object\n",
    "distances_graph = [TrainDistanceMixin(distance = ipsen_mikailov), TrainDistanceMixin(distance = portrait)]\n",
    "data.add_data(graph_features, distances_graph)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I know it's a little bit of writing, but don't worry if you have just a simple numerical data you can just go with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rsif.forest import RandomSimilarityIsolationForest\n",
    "\n",
    "data = np.random.randn(100,10)\n",
    "forest = RandomSimilarityIsolationForest().fit(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coming back to our example. `RsifData` inheriths from a list and add few additional features. So if you want you can easily iterate over previously added data and distance functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [2]\n",
      " [1]] int32 [<risf.distance.TrainDistanceMixin object at 0x0000015FD2FCEAA0>]\n",
      "[[1.77 -0.347 0.67]\n",
      " [0.322 0.0603 -1.04]\n",
      " [-1.01 0.442 1.13]] float64 [<risf.distance.TrainDistanceMixin object at 0x0000015FD2FCDAE0>, <risf.distance.TrainDistanceMixin object at 0x0000015FD2FCDB40>]\n",
      "[{10, 20, 30} {20, 30} {10, 20}] object [<risf.distance.TrainDistanceMixin object at 0x0000015FD2FCCA60>]\n",
      "[<__main__.Graph object at 0x0000015FD2FCDC30> <__main__.Graph object at 0x0000015FD2FCDD50> <__main__.Graph object at 0x0000015FD2FCF430>] object [<risf.distance.TrainDistanceMixin object at 0x0000015FD2FCE2F0>, <risf.distance.TrainDistanceMixin object at 0x0000015FD2FCF3D0>]\n"
     ]
    }
   ],
   "source": [
    "for i, feature in enumerate(data):\n",
    "    print(feature, feature.dtype, data.distances[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to fit the model you would just do \n",
    "\n",
    "```python\n",
    "forest = RandomIsolationSimilarityForest(distances = data.distances).fit(data)\n",
    "```\n",
    "\n",
    "Very important step hapenning inside fit function is parsing this Rsif Data container into plain numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rsif.utils.validation import prepare_X\n",
    "\n",
    "parsed_data, features_span = prepare_X(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 1.77, -0.347, 0.67, 0, 0],\n",
       "        [2, 0.322, 0.0603, -1.04, 1, 1],\n",
       "        [1, -1.01, 0.442, 1.13, 2, 2]]),\n",
       " [(0, 1), (1, 4), (4, 5), (5, 6)])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_data, features_span"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see data was merged into one big table. Moreover every feature got it's own feature span. You may wonder why instead of sets and graphs objects we have this indices. for internal operations of the algorithm to make it much faster we replace object with it's indices. This will become easier after we describe `SelectiveDistance` and `TrainDistanceMixin`.\n",
    "\n",
    "But just to finish this part fit procedure at every split performs such operations:\n",
    "1. Get non unique features -> if there are 0 set_node to be a leaf\n",
    "2. Select feature randomly\n",
    "3. Select one of the available distances randomly\n",
    "4. project data w.r.t selected feature\n",
    "5. randomly select split point"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distances\n",
    "\n",
    "We have two types of distances objects:\n",
    "* `SelectiveDistance` - use it when your projection function is very cheap to calculate (Euclidean, Cosine etc.)\n",
    "* `TrainDistanceMixin` - use it for complex objects when distance computation can take substantial amount of time.\n",
    "\n",
    "\n",
    "SelectiveDistance can be created as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rsif.distance_functions import euclidean_projection\n",
    "random_number_generator = np.random.RandomState(23)\n",
    "\n",
    "X = np.random.randn(10, 10)\n",
    "Oi = X[0]\n",
    "Oj = X[1]\n",
    "distance = SelectiveDistance(projection_func = euclidean_projection, min_n=1, max_n=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the question is why we need this min_n and max_n. The two parameters balances between simply Isolation Forest behaviour - selecting individual attributes or Similarity Forest - taking into account entire objects. With setup as above size of selected vector is chosen randomly at every step and we can use at most 5 features at a time. So this setup is closer to the Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.3 -4.03 0.893 -0.272 4.41 0.215 -1.59 1.37 -2.08 2.67]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5, 7, 2, 3])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = Tree()\n",
    "result = distance.project(X, Oi, Oj, tree, random_number_generator) # we pass random number generator to make the result reproducible\n",
    "print(result)\n",
    "tree.selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0374 -2.6 -1.58 2.47 -1.83 0.657 -0.39 2.1 -1.58 -1.4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree1 = Tree()\n",
    "result = distance.project(X, Oi, Oj, tree1, random_number_generator) # we pass random number generator to make the result reproducible\n",
    "print(result)\n",
    "tree1.selected_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as you can see this is quite powerful mechanism. By setting $min_n$ and $max_n$ to $1$ we obtain `Isolation Forest` like behaviour. By setting $min_n$ and $max_n$ to $n_dim$ we obtain `Similarity Forest` like behaviour. Additionaly, we can explore everything in between.\n",
    "\n",
    "Train distance mixin basically allows you to precompute distance matrix once and reuse it anytime. It is very useful when distance calculation is expensive e.g for graph distances.\n",
    "\n",
    "To present inner working of this class I will use unit tests :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rsif.distance import TrainDistanceMixin\n",
    "\n",
    "class MockDist:\n",
    "    def __init__(self):\n",
    "        self.i = 0\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        self.i += 1\n",
    "        return self.i\n",
    "    \n",
    "N_TRAIN_OBJECTS = 5\n",
    "X = np.empty(N_TRAIN_OBJECTS, dtype=object)\n",
    "X[:] = object()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3, 4],\n",
       "       [1, 0, 5, 6, 7],\n",
       "       [2, 5, 0, 8, 9],\n",
       "       [3, 6, 8, 0, 10],\n",
       "       [4, 7, 9, 10, 0]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance = TrainDistanceMixin(distance=MockDist())\n",
    "distance.precompute_distances(X, n_jobs=1)\n",
    "distance.distance_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as you can see we have our distances precomputed. Now our Trees can use it. But what if computations are extremely heavy? We can restrict number of available objects for pairs creations, we've empirically shown that this doesn't deteriorate performance of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 5],\n",
       "       [0, 0, 2, 0, 6],\n",
       "       [1, 2, 0, 3, 4],\n",
       "       [0, 0, 3, 0, 7],\n",
       "       [5, 6, 4, 7, 0]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance = TrainDistanceMixin(distance=MockDist())\n",
    "distance.selected_objects = [2, 4]\n",
    "distance.precompute_distances(X, n_jobs = 1)\n",
    "distance.distance_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now during fitting our forest it will be prohibited to use different objects than 2nd and 4th for this particular feature. If you remember RsifData you can set n_selected_objects to some integer which will automatically perform all the stuff for you\n",
    "\n",
    "```python\n",
    "data = RsifData()\n",
    "```\n",
    "\n",
    "Moreover you don't need to run this precompute_distances manually, as you created RsifData object just run\n",
    "\n",
    "```python\n",
    "data.precompute_distances()\n",
    "```\n",
    "\n",
    "And finally\n",
    "```python\n",
    "forest.fit(data)\n",
    "```\n",
    "\n",
    "These are basically all concepts that should be important to you during testing this solution. Now, sky is the limit :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "random-isolation-similarity-forest-bqxKmFq8-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
