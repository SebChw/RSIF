{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case study\n",
    "#### Using RISF on real life data from bus sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "import datetime\n",
    "import pickle\n",
    "from csutils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestamp conversion copied from buses-data-demo.ipynb\n",
    "VACT_EPOCH = datetime.datetime(year=2011,month=6,day=16,hour=5,minute=23,second=0)\n",
    "VACT_TIMESTAMP = 1308194580\n",
    "assert datetime.datetime.fromtimestamp(VACT_TIMESTAMP) == VACT_EPOCH\n",
    "MILISECOND = 1\n",
    "SECOND = 1000 * MILISECOND\n",
    "HOUR = 3600*SECOND\n",
    "DAY = 24*HOUR\n",
    "def getVactDate(value):\n",
    "    return VACT_EPOCH + datetime.timedelta(milliseconds=int(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading pandas DataFrame with recorded values from sensors and\n",
    "# Adding column with transformed timestamp\n",
    "# Note that this data is ignored by git, so you have to make a copy on your own\n",
    "# Also the excel file seems to only contain data about the bus number 369\n",
    "# TODO Remove these links\n",
    "# Link to data:\n",
    "# https://halmstaduniversity.box.com/s/rtm3o8dzdt4o0hxr5sredhb1y06qsi8u\n",
    "\n",
    "DATA_369 = pickle.load(open(\"../data/bus/data-369.pickle\",\"rb\"))\n",
    "DATA_370 = pickle.load(open(\"../data/bus/data-370.pickle\",\"rb\"))\n",
    "DATA_371 = pickle.load(open(\"../data/bus/data-371.pickle\",\"rb\"))\n",
    "DATA_372 = pickle.load(open(\"../data/bus/data-372.pickle\",\"rb\"))\n",
    "DATA_375 = pickle.load(open(\"../data/bus/data-375.pickle\",\"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_369 = DATA_369.set_index('tstamp')\n",
    "DATA_369.sort_index(inplace = True)\n",
    "DATA_370 = DATA_370.set_index('tstamp')\n",
    "DATA_370.sort_index(inplace = True)\n",
    "DATA_371 = DATA_371.set_index('tstamp')\n",
    "DATA_371.sort_index(inplace = True)\n",
    "DATA_372 = DATA_372.set_index('tstamp')\n",
    "DATA_372.sort_index(inplace = True)\n",
    "DATA_375 = DATA_375.set_index('tstamp')\n",
    "DATA_375.sort_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_369.drop(columns=['Timestamp'], inplace = True)\n",
    "DATA_370.drop(columns=['Timestamp'], inplace = True)\n",
    "DATA_371.drop(columns=['Timestamp'], inplace = True)\n",
    "DATA_372.drop(columns=['Timestamp'], inplace = True)\n",
    "DATA_375.drop(columns=['Timestamp'], inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['WetTankAirPressure', 'EngineAirInletPressure']\n",
    "\n",
    "X_dfs = [DATA_370,DATA_371,DATA_372,DATA_375]\n",
    "y_dfs = [DATA_369]\n",
    "\n",
    "for X in X_dfs:\n",
    "    X = X.loc[:,columns]\n",
    "\n",
    "START = pd.Timestamp('2012-04-15 08:23:47.763000') \n",
    "END = START + pd.Timedelta('4W')\n",
    "\n",
    "FREQ = pd.Timedelta('4T')  \n",
    "WINDOW_SIZE = pd.Timedelta('4T')\n",
    "\n",
    "def bin10(column): return 10\n",
    "AVG_SIZE = '1S'\n",
    "\n",
    "X_NUMERIC = []\n",
    "X_HISTOGRAM = []\n",
    "X_TSIRES = []\n",
    "\n",
    "y_NUMERIC = []\n",
    "y_HISTOGRAM = []\n",
    "y_TSIRES = []\n",
    "y_TSTAMPS = []\n",
    "\n",
    "for X in X_dfs:\n",
    "    for win in extract_time_windows(X, WINDOW_SIZE, start=START, end=END, freq=FREQ):\n",
    "        n = win.shape[0]\n",
    "        if n < 20:\n",
    "            continue\n",
    "        X_NUMERIC.append(get_numeric_from_window(win))\n",
    "        X_HISTOGRAM.append(get_histograms_from_window(win, way_of_binarization=bin10))\n",
    "        X_TSIRES.append(get_time_series_from_window(win,AVG_SIZE=AVG_SIZE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in y_dfs:\n",
    "    for timed_win in extract_time_windows(y, WINDOW_SIZE, timestamp = True, start=START, end=END, freq=FREQ):\n",
    "        tstamp, win = timed_win\n",
    "        n = win.shape[0]\n",
    "        if n < 20:\n",
    "            continue\n",
    "        y_TSTAMPS.append(tstamp)\n",
    "        y_NUMERIC.append(get_numeric_from_window(win))\n",
    "        y_HISTOGRAM.append(get_histograms_from_window(win, way_of_binarization=bin10))\n",
    "        y_TSIRES.append(get_time_series_from_window(win,AVG_SIZE=AVG_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nan_to_num(X_NUMERIC, copy=False)\n",
    "np.nan_to_num(y_NUMERIC, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(columns)):\n",
    "    num_col = X_NUMERIC[:][i]\n",
    "    num_col = np.array(num_col)\n",
    "    print(num_col[:10])\n",
    "    print(num_col.shape)\n",
    "    hist_col = X_HISTOGRAM[:][i]\n",
    "    hist_col = np.array(hist_col, dtype=object)\n",
    "    print(hist_col[:10])\n",
    "    print(hist_col.shape)\n",
    "    tser_col = X_TSIRES[:][i]\n",
    "    tser_col = np.array(tser_col)\n",
    "    print(tser_col[:10])\n",
    "    print(tser_col.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from risf.risf_data import RisfData\n",
    "from risf.forest import *\n",
    "from risf.distance import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from risf.distance_functions import * \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from risf.distance_functions import * \n",
    "ex_X = RisfData()\n",
    "ex_y = RisfData()\n",
    "\n",
    "\n",
    "class MyWasser():\n",
    "    def __init__(self) -> None:\n",
    "        self.results = {}\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.dist(*args, **kwargs)\n",
    "    \n",
    "    def dist(self, hist1, hist2):\n",
    "        bins1, values1 = hist1\n",
    "        bins2, values2 = hist2\n",
    "\n",
    "        #dist = wasserstein_distance(values1, values2, bins1, bins2)\n",
    "        dist = wasserstein_distance(values1, values2)\n",
    "        self.results[\"dist\"] = dist\n",
    "        print(dist)\n",
    "        return dist\n",
    "\n",
    "# class MyEuclidean():\n",
    "#     def __init__(self) -> None:\n",
    "#         self.results = {}\n",
    "\n",
    "#     def __call__(self, *args, **kwargs):\n",
    "#         return self.dist(*args, **kwargs)\n",
    "\n",
    "#     def adjust(self, values1, bins1, values2, bins2):\n",
    "#         min1, max1 = min(bins1), max(bins1)\n",
    "#         min2, max2 = min(bins2), max(bins2)\n",
    "\n",
    "#         bins = np.arange(min(min1, min2), max(max1, max2) + 1)\n",
    "\n",
    "#         values1_new = [0] * len(bins)\n",
    "#         for bin in bins1:\n",
    "#             i = np.where(bins == bin)[0][0]\n",
    "#             j = np.where(bins1 == bin)[0][0]\n",
    "#             values1_new[i] = values1[j]\n",
    "#         values2_new = [0] * len(bins)\n",
    "#         for bin in bins2:\n",
    "#             i = np.where(bins == bin)[0][0]\n",
    "#             j = np.where(bins2 == bin)[0][0]\n",
    "#             values2_new[i] = values2[j]\n",
    "#         return values1_new, values2_new\n",
    "\n",
    "#     def dist(self, hist1, hist2):\n",
    "#         bins1, values1 = hist1\n",
    "#         bins2, values2 = hist2\n",
    "#         if not np.array_equal(bins1, bins2):\n",
    "#             bins1, bins2 = np.array(bins1), np.array(bins2)\n",
    "#             values1, values2 = self.adjust(values1, bins1, values2, bins2)\n",
    "#         values1, values2 = np.array(values1), np.array(values2)\n",
    "\n",
    "#         dist = np.linalg.norm(values1 - values2) ** 2\n",
    "#         self.results[\"dist\"] = dist\n",
    "#         return dist\n",
    "\n",
    "\n",
    "# distances_numerical = [SelectiveDistance(projection_func = euclidean_projection, min_n=1, max_n=3),\n",
    "#                         SelectiveDistance(projection_func = cosine_projection, min_n=1, max_n=3)]\n",
    "\n",
    "distances_histogram = [\n",
    "    TrainDistanceMixin(distance = MyWasser()),\n",
    "    ##TrainDistanceMixin(distance = MyEuclidean())\n",
    "    ]\n",
    "\n",
    "#distanecs_tser = [TrainDistanceMixin(distance = TSEuclidean())]\n",
    "\n",
    "for i in range(len(columns)):\n",
    "    # num_col = X_NUMERIC[:][i]\n",
    "    # num_col = np.array(num_col)\n",
    "    # ex_X.add_data(num_col, distances_numerical)\n",
    "    hist_col = X_HISTOGRAM[:][i]\n",
    "    hist_col = np.array(hist_col, dtype=object)\n",
    "    ex_X.add_data(hist_col, distances_histogram)\n",
    "    # tser_col = X_TSIRES[:][i]\n",
    "    # tser_col = np.array(tser_col)\n",
    "    # ex_X.add_data(tser_col, distanecs_tser)\n",
    "    \n",
    "    # num_col = y_NUMERIC[:][i]\n",
    "    # num_col = np.array(num_col)\n",
    "    # ex_y.add_data(num_col, distances_numerical)\n",
    "    hist_col = y_HISTOGRAM[:][i]\n",
    "    hist_col = np.array(hist_col, dtype=object)\n",
    "    ex_y.add_data(hist_col, distances_histogram)\n",
    "    # tser_col = y_TSIRES[:][i]\n",
    "    # hist_col = np.array(tser_col)\n",
    "    # ex_y.add_data(tser_col, distanecs_tser)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_X.precompute_distances()\n",
    "ex_y.precompute_distances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomIsolationSimilarityForest(distances = ex_X.distances).fit(ex_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = forest.predict(ex_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nr. Mode        Start time End time   Failure alarm\n",
    "#1  planned     2012-02-02 2012-02-09 2012-02-01\n",
    "#2  planned     2012-03-01 2012-03-02 2012-02-29\n",
    "#3  unplanned   2012-03-05 2012-03-05 2012-03-03\n",
    "#4  unplanned   2012-03-16 2012-03-19 2012-03-14\n",
    "#5  unplanned   2012-04-01 2012-04-13 2012-03-31\n",
    "#6  planned     2012-05-29 2012-05-29 2012-05-29\n",
    "#7  unplanned   2012-07-10 2012-07-23 2012-07-10\n",
    "#8  planned     2012-08-21 2012-08-23 2012-08-21\n",
    "#9  unplanned   2012-10-08 2012-10-08 2012-10-08\n",
    "#10 planned     2012-12-27 2012-12-28 2012-12-25\n",
    "#11 planned     2013-02-19 2013-03-06 2013-02-19\n",
    "#12 unplanned   2013-04-23 2013-04-24 2013-04-22\n",
    "#13 unplanned   2013-04-29 2013-04-29 -\n",
    "#14 unplanned   2013-07-11 2013-07-19 2013-07-11\n",
    "#15 planned     2013-08-12 2013-08-16 2013-08-12\n",
    "#16 unplanned   2013-12-11 2013-12-19 2013-12-10\n",
    "#17 planned     2014-01-09 2014-01-09 2014-01-09\n",
    "#18 planned     2014-01-31 2014-02-11 2014-01-31\n",
    "#19 unplanned   2014-02-23 2014-02-23 2014-02-22\n",
    "#20 unplanned   2014-03-13 2014-03-20 2014-03-12\n",
    "#21 unplanned   2014-04-14 2014-04-14 2014-04-13\n",
    "#22 unplanned   2014-04-20 2014-04-20 -\n",
    "#23 unplanned   2014-06-08 2014-06-08 2014-06-05\n",
    "#24 unplanned   2014-08-14 2014-08-15 -\n",
    "#25 planned     2014-09-03 2014-09-05 2014-09-03\n",
    "#26 planned     2014-11-28 2014-11-28 -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
