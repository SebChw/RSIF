{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic experiments\n",
    "\n",
    "Experiments comparing Random Isolation Similarity Forest to other outlier (anomaly) detection algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from data.SF_outliers_data import get_datasets\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use different outlier detection algorithms to compare to RISF:\n",
    "* LOF\n",
    "* ECOD\n",
    "* Isolation Forest\n",
    "* HBOS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.ecod import ECOD\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.hbos import HBOS\n",
    "#import RISF here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 23\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will measure AUC (as a binary classification task of being an outlier) and processing time. We can show plots for every algorithm and the top-N feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = get_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kddcup99_http\n",
      "kddcup99_sf\n",
      "kddcup99_sa\n",
      "forestcover\n",
      "breastw\n"
     ]
    }
   ],
   "source": [
    "# loop for training\n",
    "for X_train, X_test, y_train, y_test, name in datasets:\n",
    "    print(name)\n",
    "    data[name] = [X_train, X_test, y_train, y_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.utils.data import evaluate_print\n",
    "from pyod.utils.example import visualize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.15993384, -0.1962505 ,  0.5445351 , ..., -0.09555247,\n",
       "        -0.25415296, -0.25241887],\n",
       "       [-0.15993384, -0.1962505 , -1.83642891, ..., -0.09555247,\n",
       "        -0.25415296, -0.25241887],\n",
       "       [-0.15993384, -0.1962505 ,  0.5445351 , ..., -0.09555247,\n",
       "        -0.25415296, -0.25241887],\n",
       "       ...,\n",
       "       [-0.15993384, -0.1962505 ,  0.5445351 , ..., -0.09555247,\n",
       "         4.2221208 ,  3.8395796 ],\n",
       "       [-0.15993384, -0.1962505 ,  0.5445351 , ..., -0.09555247,\n",
       "        -0.25415296, -0.25241887],\n",
       "       [-0.15993384, -0.1962505 ,  0.5445351 , ..., -0.09555247,\n",
       "        -0.25415296, -0.25241887]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['kddcup99_sa'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_clf(name):\n",
    "    if name == 'ECOD':\n",
    "        return ECOD()\n",
    "    if name == 'LOF':\n",
    "        return LOF()\n",
    "    if name == 'IForest':\n",
    "        return IForest()\n",
    "    if name == 'HBOS':\n",
    "        return HBOS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "kddcup99_sf:\n",
      "On Training Data:\n",
      "ECOD ROC:0.8183, precision @ rank n:0.1331\n",
      "On Test Data:\n",
      "ECOD ROC:0.8201, precision @ rank n:0.1301\n",
      "On Training Data:\n",
      "LOF ROC:0.3847, precision @ rank n:0.0702\n",
      "On Test Data:\n",
      "LOF ROC:0.3421, precision @ rank n:0.0625\n",
      "On Training Data:\n",
      "IForest ROC:0.9321, precision @ rank n:0.1649\n",
      "On Test Data:\n",
      "IForest ROC:0.9329, precision @ rank n:0.1602\n",
      "On Training Data:\n",
      "HBOS ROC:0.842, precision @ rank n:0.1496\n",
      "On Test Data:\n",
      "HBOS ROC:0.8433, precision @ rank n:0.1183\n",
      "\n",
      "\n",
      "kddcup99_sa:\n",
      "On Training Data:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [33], line 23\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39m# evaluate and print the results\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mOn Training Data:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m evaluate_print(clf_name, y_train\u001b[39m.\u001b[39;49mastype(\u001b[39m'\u001b[39;49m\u001b[39mint\u001b[39;49m\u001b[39m'\u001b[39;49m), y_train_scores)\n\u001b[0;32m     24\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mOn Test Data:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m evaluate_print(clf_name, y_test\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mint\u001b[39m\u001b[39m'\u001b[39m), y_test_scores)\n",
      "File \u001b[1;32md:\\polibuda\\sem5\\Isolation-Similarity-Forest\\.venv\\lib\\site-packages\\pyod\\utils\\data.py:297\u001b[0m, in \u001b[0;36mevaluate_print\u001b[1;34m(clf_name, y, y_pred)\u001b[0m\n\u001b[0;32m    292\u001b[0m y_pred \u001b[39m=\u001b[39m column_or_1d(y_pred)\n\u001b[0;32m    293\u001b[0m check_consistent_length(y, y_pred)\n\u001b[0;32m    295\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m{clf_name}\u001b[39;00m\u001b[39m ROC:\u001b[39m\u001b[39m{roc}\u001b[39;00m\u001b[39m, precision @ rank n:\u001b[39m\u001b[39m{prn}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    296\u001b[0m     clf_name\u001b[39m=\u001b[39mclf_name,\n\u001b[1;32m--> 297\u001b[0m     roc\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mround(roc_auc_score(y, y_pred), decimals\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m),\n\u001b[0;32m    298\u001b[0m     prn\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mround(precision_n_scores(y, y_pred), decimals\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)))\n",
      "File \u001b[1;32md:\\polibuda\\sem5\\Isolation-Similarity-Forest\\.venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:550\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    548\u001b[0m y_type \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    549\u001b[0m y_true \u001b[39m=\u001b[39m check_array(y_true, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m--> 550\u001b[0m y_score \u001b[39m=\u001b[39m check_array(y_score, ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    552\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m (\n\u001b[0;32m    553\u001b[0m     y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m y_score\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m y_score\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m    554\u001b[0m ):\n\u001b[0;32m    555\u001b[0m     \u001b[39m# do not support partial ROC computation for multiclass\u001b[39;00m\n\u001b[0;32m    556\u001b[0m     \u001b[39mif\u001b[39;00m max_fpr \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m max_fpr \u001b[39m!=\u001b[39m \u001b[39m1.0\u001b[39m:\n",
      "File \u001b[1;32md:\\polibuda\\sem5\\Isolation-Similarity-Forest\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:899\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    893\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    894\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    895\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    896\u001b[0m         )\n\u001b[0;32m    898\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 899\u001b[0m         _assert_all_finite(\n\u001b[0;32m    900\u001b[0m             array,\n\u001b[0;32m    901\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[0;32m    902\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[0;32m    903\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    904\u001b[0m         )\n\u001b[0;32m    906\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    907\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32md:\\polibuda\\sem5\\Isolation-Similarity-Forest\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:146\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    125\u001b[0m             \u001b[39mnot\u001b[39;00m allow_nan\n\u001b[0;32m    126\u001b[0m             \u001b[39mand\u001b[39;00m estimator_name\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    131\u001b[0m             \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    132\u001b[0m             msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    133\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    134\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    144\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    145\u001b[0m             )\n\u001b[1;32m--> 146\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n\u001b[0;32m    148\u001b[0m \u001b[39m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39melif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nan:\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "clfs_names = ['ECOD', 'LOF', 'IForest', 'HBOS']\n",
    "for key, item in data.items():\n",
    "    if key == 'kddcup99_http':\n",
    "        continue\n",
    "    print(f'\\n\\n{key}:')\n",
    "    for clf_name in clfs_names:\n",
    "        clf = get_new_clf(clf_name)\n",
    "        X_train, X_test, y_train, y_test = item\n",
    "        clf.fit(X_train)\n",
    "        \n",
    "        # get the prediction labels and outlier scores of the training data\n",
    "        y_train_pred = clf.labels_  # binary labels (0: inliers, 1: outliers)\n",
    "        y_train_scores = clf.decision_scores_  # raw outlier scores\n",
    "\n",
    "        # get the prediction on the test data\n",
    "        y_test_pred = clf.predict(X_test)  # outlier labels (0 or 1)\n",
    "        y_test_scores = clf.decision_function(X_test)  # outlier scores\n",
    "        # evaluate and print the results\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"On Training Data:\")\n",
    "        evaluate_print(clf_name, y_train.astype('int'), y_train_scores)\n",
    "        print(\"On Test Data:\")\n",
    "        evaluate_print(clf_name, y_test.astype('int'), y_test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, ..., nan, nan, nan])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data['kddcup99_sa'][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b56e3c97de72a7673ee0fcfb94642a98e5ba521673e7fa53275c57ef5fa8664"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
