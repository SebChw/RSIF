{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "Experiments comparing Random Isolation Similarity Forest to other outlier (anomaly) detection algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(0, '../data')\n",
    "from data_getter import get_numerical_datasets, get_graphs\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyod.utils.utility import precision_n_scores\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "from notebooks.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use different outlier detection algorithms to compare to RISF:\n",
    "* LOF\n",
    "* ECOD\n",
    "* Isolation Forest\n",
    "* HBOS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will measure AUC (as a binary classification task of being an outlier) and processing time. We can show plots for every algorithm and the top-N feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs_names = ['ECOD', 'LOF', 'IForest', 'HBOS', 'RISF']\n",
    "results = {x: {} for x in clfs_names}\n",
    "resultsY = results.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer = Timer(timer_type=\"long_running\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Datasets (outer loop): 0it [03:55, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "datasets_loop = tqdm(get_numerical_datasets(), desc=\"Datasets (outer loop)\", position=0)\n",
    "algorithms_loop = tqdm(clfs_names, desc=\" Algorithms (inner loop)\", position=1, leave=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only X known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23_WPBC.npz: : 23it [55:53, 145.80s/it]          \n"
     ]
    }
   ],
   "source": [
    "for data in datasets_loop:\n",
    "    datasets_loop.set_description(data['name'])\n",
    "    for clf_name in algorithms_loop:\n",
    "        algorithms_loop.set_description(clf_name)\n",
    "        clf = new_clf(clf_name, SEED)\n",
    "        timer.start()\n",
    "        clf.fit(data['X_train'])\n",
    "        timer.stop()\n",
    "        train_time = timer.time_sec\n",
    "        \n",
    "        # get the prediction labels and outlier scores of the training and tests  data\n",
    "        if clf_name == 'RISF': # other libs return sklearn UndefinedMetricWarning from predicting th train data\n",
    "            y_train_pred = clf.predict(data['X_train']) # binary labels (0: inliers, 1: outliers)\n",
    "        else:\n",
    "            y_train_pred = clf.labels_\n",
    "        \n",
    "        timer.start()\n",
    "        y_test_pred = clf.predict(data['X_test'])\n",
    "        timer.stop()\n",
    "        test_time = timer.time_sec\n",
    "\n",
    "        if np.isnan(y_train_pred).any():\n",
    "            results[clf_name][data['name']] = (np.nan, np.nan, np.nan, np.nan, \n",
    "                                               np.nan, np.nan, np.nan, np.nan) \n",
    "                                               # AUC/ROC, Rank@N for train,test ; fit/test Time\n",
    "            continue\n",
    "        \n",
    "        roc_train=np.round(roc_auc_score(data['y_train'], y_train_pred), decimals=4)\n",
    "        precision_train=np.round(precision_score(data['y_train'], y_train_pred), decimals=4)\n",
    "        recall_train=np.round(recall_score(data['y_train'], y_train_pred), decimals=4)\n",
    "        roc_test=np.round(roc_auc_score(data['y_test'], y_test_pred), decimals=4)\n",
    "        precision_test=np.round(precision_score(data['y_test'], y_test_pred), decimals=4)\n",
    "        recall_test=np.round(recall_score(data['y_test'], y_test_pred), decimals=4)\n",
    "\n",
    "        results[clf_name][data['name']] = (roc_train, precision_train, recall_train,\n",
    "                                           roc_test, precision_test, recall_test,\n",
    "                                           train_time, test_time)\n",
    "        df = pd.DataFrame(results)\n",
    "        df.to_pickle('../results/numerical_temporary.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df.to_pickle('../results/numerical_selected.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training test provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23_WPBC.npz: : 24it [2:31:05, 377.72s/it]        \n"
     ]
    }
   ],
   "source": [
    "for data in datasets_loop:\n",
    "    datasets_loop.set_description(data['name'])\n",
    "    for clf_name in algorithms_loop:\n",
    "        algorithms_loop.set_description(clf_name)\n",
    "        clf = new_clf(clf_name, SEED)\n",
    "        timer.start()\n",
    "        clf.fit(data['X_train'], data['y_train'])\n",
    "        timer.stop()\n",
    "        train_time = timer.time_sec\n",
    "        \n",
    "        # get the prediction labels and outlier scores of the training and tests  data\n",
    "        if clf_name == 'RISF': # other libs return sklearn UndefinedMetricWarning from predicting th train data\n",
    "            y_train_pred = clf.predict(data['X_train']) # binary labels (0: inliers, 1: outliers)\n",
    "        else:\n",
    "            y_train_pred = clf.labels_\n",
    "        \n",
    "        timer.start()\n",
    "        y_test_pred = clf.predict(data['X_test'])\n",
    "        timer.stop()\n",
    "        test_time = timer.time_sec\n",
    "\n",
    "        if np.isnan(y_train_pred).any():\n",
    "            resultsY[clf_name][data['name']] = (np.nan, np.nan, np.nan, np.nan, \n",
    "                                               np.nan, np.nan, np.nan, np.nan) \n",
    "                                               # AUC/ROC, Rank@N for train,test ; fit/test Time\n",
    "            continue\n",
    "        \n",
    "        roc_train=np.round(roc_auc_score(data['y_train'], y_train_pred), decimals=4)\n",
    "        precision_train=np.round(precision_score(data['y_train'], y_train_pred), decimals=4)\n",
    "        recall_train=np.round(recall_score(data['y_train'], y_train_pred), decimals=4)\n",
    "        roc_test=np.round(roc_auc_score(data['y_test'], y_test_pred), decimals=4)\n",
    "        precision_test=np.round(precision_score(data['y_test'], y_test_pred), decimals=4)\n",
    "        recall_test=np.round(recall_score(data['y_test'], y_test_pred), decimals=4)\n",
    "\n",
    "        resultsY[clf_name][data['name']] = (roc_train, precision_train, recall_train,\n",
    "                                           roc_test, precision_test, recall_test,\n",
    "                                           train_time, test_time)\n",
    "        df = pd.DataFrame(resultsY)\n",
    "        df.to_pickle('../results/numerical_temporary.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(resultsY)\n",
    "df.to_pickle('../results/numerical_y.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRAPHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from risf.distance_functions import DegreeDivergenceDist, JaccardDist\n",
    "from risf.risf_data import RisfData\n",
    "from data.data_getter import get_graphs, get_ucr_time_series, get_glocalkd_dataset\n",
    "from risf.forest import RandomIsolationSimilarityForest\n",
    "from collections import defaultdict\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "clfs_names = [\"IForest\", \"ISF\", 'ECOD', 'LOF', 'HBOS', \"RISF\"]\n",
    "results = defaultdict(lambda : defaultdict(lambda: {}))\n",
    "\n",
    "#datasets_loop = tqdm(get_graphs(), desc=\"Datasets (outer loop)\", position=0)\n",
    "DATA_DIR = \"../data/graph\"\n",
    "datasets_loop = [\"NCI1\", \"REDDIT-BINARY\", \"PPAR-gamma\"]\n",
    "distances = np.array([\"JaccardDist\", \"DegreeDivergenceDist\"], dtype=object)\n",
    "algorithms_loop = tqdm(clfs_names, desc=\" Algorithms (inner loop)\", position=1, leave=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_to_use = np.array([list(option) for option \n",
    "                            in itertools.product([True, False], repeat=len(distances))\n",
    "                            if list(option) != [False]*len(distances)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_scores(results, clf_name, data, y_train_pred, y_test_pred):\n",
    "        auc_train = np.round(roc_auc_score(data[\"y_train\"], y_train_pred), decimals=4)\n",
    "        auc_test = np.round(roc_auc_score(data[\"y_test\"], y_test_pred), decimals=4)\n",
    "\n",
    "        results['train'][clf_name][data['name']] = auc_train\n",
    "        results['test'][clf_name][data['name']] = auc_test\n",
    "\n",
    "        print(f\"{clf_name}, on {data['name']} obtained, auc_train: {auc_train} and auc_test: {auc_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No node attributes\n",
      "train_counts (array([0, 1]), array([1437,  144], dtype=int64))\n",
      "test_counts (array([0, 1]), array([616, 617], dtype=int64))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "make_X_numeric() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m dataset_name \u001b[39min\u001b[39;00m datasets_loop:\n\u001b[1;32m----> 2\u001b[0m     data \u001b[39m=\u001b[39m get_glocalkd_dataset(DATA_DIR, dataset_name)\n\u001b[0;32m      3\u001b[0m     \u001b[39mfor\u001b[39;00m clf_name \u001b[39min\u001b[39;00m algorithms_loop:\n\u001b[0;32m      4\u001b[0m         algorithms_loop\u001b[39m.\u001b[39mset_description(clf_name)\n",
      "File \u001b[1;32mD:\\AI_y3_s1\\ProblemClasses\\Isolation-Similarity-Forest\\data\\data_getter.py:207\u001b[0m, in \u001b[0;36mget_glocalkd_dataset\u001b[1;34m(data_dir, dataset_name)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrain_counts \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39munique(y_train, return_counts\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    203\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtest_counts \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39munique(y_test, return_counts\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    205\u001b[0m \u001b[39mreturn\u001b[39;00m {\n\u001b[0;32m    206\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mX_train\u001b[39m\u001b[39m\"\u001b[39m: X_train,\n\u001b[1;32m--> 207\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mX_train_num\u001b[39m\u001b[39m\"\u001b[39m: make_X_numeric(X_train, dataset_name),\n\u001b[0;32m    208\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39my_train\u001b[39m\u001b[39m\"\u001b[39m: y_train,\n\u001b[0;32m    209\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mX_test\u001b[39m\u001b[39m\"\u001b[39m: X_test,\n\u001b[0;32m    210\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mX_test_num\u001b[39m\u001b[39m\"\u001b[39m: make_X_numeric(X_test, dataset_name),\n\u001b[0;32m    211\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39my_test\u001b[39m\u001b[39m\"\u001b[39m: y_test,\n\u001b[0;32m    212\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: dataset_name\n\u001b[0;32m    213\u001b[0m }\n",
      "\u001b[1;31mTypeError\u001b[0m: make_X_numeric() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "for dataset_name in datasets_loop:\n",
    "    data = get_glocalkd_dataset(DATA_DIR, dataset_name)\n",
    "    for clf_name in algorithms_loop:\n",
    "        algorithms_loop.set_description(clf_name)\n",
    "    \n",
    "        if clf_name == \"RISF\":\n",
    "            for dist_to_use in distances_to_use:\n",
    "                dist = distances[dist_to_use]\n",
    "                X_risf = RisfData()\n",
    "                X_risf.add_data(data[\"X_train\"], dist = [f\"../precomputed_distances/{dataset_name}_{d}_train.pickle\" for d in dist])\n",
    "                X_risf.precompute_distances()\n",
    "                clf = RandomIsolationSimilarityForest(random_state=SEED, distance=X_risf.distances).fit(X_risf)\n",
    "                y_train_pred = (-1)*clf.predict(X_risf, return_raw_scores=True)\n",
    "\n",
    "                X_test_risf = clf.transform([data[\"X_test\"]], n_jobs=-2, precomputed_distances=[[f\"../precomputed_distances/{dataset_name}_{d}_test.pickle\" for d in dist]])\n",
    "                y_test_pred = (-1)*clf.predict(X_test_risf, return_raw_scores=True)\n",
    "\n",
    "                add_scores(results, f\"RISF_{'_'.join([x[:3] for x in dist])}\", data, y_train_pred, y_test_pred)\n",
    "            \n",
    "        else:\n",
    "            clf = new_clf(clf_name, SEED)\n",
    "            clf.fit(data[\"X_train_num\"])\n",
    "            y_train_pred = clf.decision_function(data[\"X_train_num\"])\n",
    "            y_test_pred = clf.decision_function(data[\"X_test_num\"])\n",
    "            \n",
    "            add_scores(results, clf_name, data, y_train_pred, y_test_pred)\n",
    "\n",
    "    # for split, result in results.items():\n",
    "    #     df = pd.DataFrame(result)\n",
    "    #     df.to_pickle(f'../results/{split}_graphs.pkl')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Datasets (outer loop): 0it [00:00, ?it/s]"
     ]
    }
   ],
   "source": [
    "clfs_names = [\"IForest\", \"ISF\", 'ECOD', 'LOF', 'HBOS', \"RISF\"]\n",
    "results = {x: {} for x in clfs_names}\n",
    "\n",
    "datasets_loop = tqdm(get_ucr_time_series(), desc=\"Datasets (outer loop)\", position=0)\n",
    "algorithms_loop = tqdm(clfs_names, desc=\" Algorithms (inner loop)\", position=1, leave=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastdtw import fastdtw\n",
    "\n",
    "def dtw(series1, series2):\n",
    "     return fastdtw(series1, series2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computers: : 0it [00:00, ?it/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IForest, on Computers obtained, auc_train: 0.352 and auc_test: 0.3747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISF, on Computers obtained, auc_train: 0.6 and auc_test: 0.448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECOD, on Computers obtained, auc_train: 0.372 and auc_test: 0.3467\n",
      "LOF, on Computers obtained, auc_train: 0.556 and auc_test: 0.588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HBOS, on Computers obtained, auc_train: 0.4093 and auc_test: 0.2947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HouseTwenty: : 1it [05:20, 320.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RISF, on Computers obtained, auc_train: 0.3187 and auc_test: 0.296\n",
      "IForest, on HouseTwenty obtained, auc_train: 1.0 and auc_test: 0.8841\n",
      "ISF, on HouseTwenty obtained, auc_train: 0.75 and auc_test: 0.087\n",
      "ECOD, on HouseTwenty obtained, auc_train: 1.0 and auc_test: 0.5604\n",
      "LOF, on HouseTwenty obtained, auc_train: 0.85 and auc_test: 0.2053\n",
      "HBOS, on HouseTwenty obtained, auc_train: 0.8 and auc_test: 0.9758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HouseTwenty: : 2it [06:33, 196.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RISF, on HouseTwenty obtained, auc_train: 0.85 and auc_test: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "high <= 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m datasets_loop:\n\u001b[0;32m      2\u001b[0m     datasets_loop\u001b[39m.\u001b[39mset_description(data[\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m     \u001b[39mfor\u001b[39;00m clf_name \u001b[39min\u001b[39;00m algorithms_loop:\n",
      "File \u001b[1;32mc:\\Users\\sebas\\AppData\\pypoetry\\virtualenvs\\random-isolation-similarity-forest-bqxKmFq8-py3.10\\lib\\site-packages\\tqdm\\std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32md:\\AI_y3_s1\\ProblemClasses\\Isolation-Similarity-Forest\\notebooks\\..\\data\\data_getter.py:150\u001b[0m, in \u001b[0;36mget_ucr_time_series\u001b[1;34m(wanted_datasets)\u001b[0m\n\u001b[0;32m    148\u001b[0m y_train[y_train \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    149\u001b[0m y_train[y_train \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 150\u001b[0m X_train, y_train \u001b[39m=\u001b[39m downsample(X_train, y_train, OUTLIERS_RATIO)\n\u001b[0;32m    152\u001b[0m X_test \u001b[39m=\u001b[39m df_test\u001b[39m.\u001b[39miloc[:, \u001b[39m1\u001b[39m:]\u001b[39m.\u001b[39mto_numpy()\n\u001b[0;32m    153\u001b[0m y_test \u001b[39m=\u001b[39m df_test\u001b[39m.\u001b[39miloc[:, \u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto_numpy()\n",
      "File \u001b[1;32md:\\AI_y3_s1\\ProblemClasses\\Isolation-Similarity-Forest\\notebooks\\..\\data\\data_getter.py:28\u001b[0m, in \u001b[0;36mdownsample\u001b[1;34m(X, y, p)\u001b[0m\n\u001b[0;32m     25\u001b[0m outs_indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(y \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[0;32m     26\u001b[0m n_outs_samples \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m(\u001b[39mlen\u001b[39m(ins_indices) \u001b[39m*\u001b[39m p)\n\u001b[1;32m---> 28\u001b[0m outs_indices_subset \u001b[39m=\u001b[39m resample(outs_indices, n_samples\u001b[39m=\u001b[39;49mn_outs_samples, random_state\u001b[39m=\u001b[39;49m\u001b[39m23\u001b[39;49m)\n\u001b[0;32m     29\u001b[0m undersampled_indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate([ins_indices, outs_indices_subset])\n\u001b[0;32m     31\u001b[0m X_undersampled \u001b[39m=\u001b[39m X[undersampled_indices]\n",
      "File \u001b[1;32mc:\\Users\\sebas\\AppData\\pypoetry\\virtualenvs\\random-isolation-similarity-forest-bqxKmFq8-py3.10\\lib\\site-packages\\sklearn\\utils\\__init__.py:573\u001b[0m, in \u001b[0;36mresample\u001b[1;34m(replace, n_samples, random_state, stratify, *arrays)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[39mif\u001b[39;00m stratify \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    572\u001b[0m     \u001b[39mif\u001b[39;00m replace:\n\u001b[1;32m--> 573\u001b[0m         indices \u001b[39m=\u001b[39m random_state\u001b[39m.\u001b[39;49mrandint(\u001b[39m0\u001b[39;49m, n_samples, size\u001b[39m=\u001b[39;49m(max_n_samples,))\n\u001b[0;32m    574\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    575\u001b[0m         indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(n_samples)\n",
      "File \u001b[1;32mmtrand.pyx:746\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_bounded_integers.pyx:1338\u001b[0m, in \u001b[0;36mnumpy.random._bounded_integers._rand_int32\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: high <= 0"
     ]
    }
   ],
   "source": [
    "for data in datasets_loop:\n",
    "    datasets_loop.set_description(data['name'])\n",
    "    for clf_name in algorithms_loop:\n",
    "        algorithms_loop.set_description(clf_name)\n",
    "        clf = new_clf(clf_name, SEED)\n",
    "\n",
    "        if clf_name == \"RISF\":\n",
    "            X_risf = RisfData()\n",
    "            X_risf.add_data(data[\"X_train\"], dist = dtw)\n",
    "            X_risf.precompute_distances(n_jobs=-2)\n",
    "            clf = RandomIsolationSimilarityForest(random_state=SEED, distance=X_risf.distances, n_jobs=-3).fit(X_risf)\n",
    "            y_train_pred = (-1)*clf.predict(X_risf, return_raw_scores=True)\n",
    "\n",
    "            X_test_risf = clf.transform([data[\"X_test\"]], n_jobs=-2)\n",
    "            y_test_pred = (-1)*clf.predict(X_test_risf, return_raw_scores=True)\n",
    "            \n",
    "        else:\n",
    "            clf.fit(data[\"X_train\"])\n",
    "            if clf_name == \"ISF\":\n",
    "                y_train_pred = clf.score_samples(data[\"X_train\"])\n",
    "                y_test_pred = clf.score_samples(data[\"X_test\"])\n",
    "            else:\n",
    "                y_train_pred = clf.decision_function(data[\"X_train\"])\n",
    "                y_test_pred = clf.decision_function(data[\"X_test\"])\n",
    "        \n",
    "        auc_train = calculate_stats(data[\"y_train\"], y_train_pred)\n",
    "        auc_test = calculate_stats(data[\"y_test\"], y_test_pred)\n",
    "\n",
    "        results[clf_name][data['name']] = (auc_train, auc_test)\n",
    "\n",
    "        print(f\"{clf_name}, on {data['name']} obtained, auc_train: {auc_train} and auc_test: {auc_test}\")\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_pickle('../results/time_series.pkl')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b56e3c97de72a7673ee0fcfb94642a98e5ba521673e7fa53275c57ef5fa8664"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
