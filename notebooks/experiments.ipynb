{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experiments\n",
        "\n",
        "Experiments comparing Random Isolation Similarity Forest to other outlier (anomaly) detection algorithms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sys\n",
        "sys.path.insert(0, '../data')\n",
        "from data.data_getter import get_numerical_datasets\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "%load_ext autoreload\n",
        "\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from pyod.utils.utility import precision_n_scores\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "from notebooks.utils import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will use different outlier detection algorithms to compare to RISF:\n",
        "* LOF\n",
        "* ECOD\n",
        "* Isolation Forest\n",
        "* HBOS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "SEED = 23"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will measure AUC (as a binary classification task of being an outlier) and processing time. We can show plots for every algorithm and the top-N feature importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "clfs_names = ['ECOD', 'LOF', 'IForest', 'HBOS', 'RISF']\n",
        "results = {x: {} for x in clfs_names}\n",
        "resultsY = results.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "timer = Timer(timer_type=\"long_running\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Datasets (outer loop): 0it [03:55, ?it/s]\n"
          ]
        }
      ],
      "source": [
        "datasets_loop = tqdm(get_numerical_datasets(), desc=\"Datasets (outer loop)\", position=0)\n",
        "algorithms_loop = tqdm(clfs_names, desc=\" Algorithms (inner loop)\", position=1, leave=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Only X known"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23_WPBC.npz: : 23it [55:53, 145.80s/it]          \n"
          ]
        }
      ],
      "source": [
        "for data in datasets_loop:\n",
        "    datasets_loop.set_description(data['name'])\n",
        "    for clf_name in algorithms_loop:\n",
        "        algorithms_loop.set_description(clf_name)\n",
        "        clf = new_clf(clf_name, SEED)\n",
        "        timer.start()\n",
        "        clf.fit(data['X_train'])\n",
        "        timer.stop()\n",
        "        train_time = timer.time_sec\n",
        "        \n",
        "        # get the prediction labels and outlier scores of the training and tests  data\n",
        "        if clf_name == 'RISF': # other libs return sklearn UndefinedMetricWarning from predicting th train data\n",
        "            y_train_pred = clf.predict(data['X_train']) # binary labels (0: inliers, 1: outliers)\n",
        "        else:\n",
        "            y_train_pred = clf.labels_\n",
        "        \n",
        "        timer.start()\n",
        "        y_test_pred = clf.predict(data['X_test'])\n",
        "        timer.stop()\n",
        "        test_time = timer.time_sec\n",
        "\n",
        "        if np.isnan(y_train_pred).any():\n",
        "            results[clf_name][data['name']] = (np.nan, np.nan, np.nan, np.nan, \n",
        "                                               np.nan, np.nan, np.nan, np.nan) \n",
        "                                               # AUC/ROC, Rank@N for train,test ; fit/test Time\n",
        "            continue\n",
        "        \n",
        "        roc_train=np.round(roc_auc_score(data['y_train'], y_train_pred), decimals=4)\n",
        "        precision_train=np.round(precision_score(data['y_train'], y_train_pred), decimals=4)\n",
        "        recall_train=np.round(recall_score(data['y_train'], y_train_pred), decimals=4)\n",
        "        roc_test=np.round(roc_auc_score(data['y_test'], y_test_pred), decimals=4)\n",
        "        precision_test=np.round(precision_score(data['y_test'], y_test_pred), decimals=4)\n",
        "        recall_test=np.round(recall_score(data['y_test'], y_test_pred), decimals=4)\n",
        "\n",
        "        results[clf_name][data['name']] = (roc_train, precision_train, recall_train,\n",
        "                                           roc_test, precision_test, recall_test,\n",
        "                                           train_time, test_time)\n",
        "        df = pd.DataFrame(results)\n",
        "        df.to_pickle('../results/numerical_temporary.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.DataFrame(results)\n",
        "df.to_pickle('../results/numerical_selected.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training test provided"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23_WPBC.npz: : 24it [2:31:05, 377.72s/it]        \n"
          ]
        }
      ],
      "source": [
        "for data in datasets_loop:\n",
        "    datasets_loop.set_description(data['name'])\n",
        "    for clf_name in algorithms_loop:\n",
        "        algorithms_loop.set_description(clf_name)\n",
        "        clf = new_clf(clf_name, SEED)\n",
        "        timer.start()\n",
        "        clf.fit(data['X_train'], data['y_train'])\n",
        "        timer.stop()\n",
        "        train_time = timer.time_sec\n",
        "        \n",
        "        # get the prediction labels and outlier scores of the training and tests  data\n",
        "        if clf_name == 'RISF': # other libs return sklearn UndefinedMetricWarning from predicting th train data\n",
        "            y_train_pred = clf.predict(data['X_train']) # binary labels (0: inliers, 1: outliers)\n",
        "        else:\n",
        "            y_train_pred = clf.labels_\n",
        "        \n",
        "        timer.start()\n",
        "        y_test_pred = clf.predict(data['X_test'])\n",
        "        timer.stop()\n",
        "        test_time = timer.time_sec\n",
        "\n",
        "        if np.isnan(y_train_pred).any():\n",
        "            resultsY[clf_name][data['name']] = (np.nan, np.nan, np.nan, np.nan, \n",
        "                                               np.nan, np.nan, np.nan, np.nan) \n",
        "                                               # AUC/ROC, Rank@N for train,test ; fit/test Time\n",
        "            continue\n",
        "        \n",
        "        roc_train=np.round(roc_auc_score(data['y_train'], y_train_pred), decimals=4)\n",
        "        precision_train=np.round(precision_score(data['y_train'], y_train_pred), decimals=4)\n",
        "        recall_train=np.round(recall_score(data['y_train'], y_train_pred), decimals=4)\n",
        "        roc_test=np.round(roc_auc_score(data['y_test'], y_test_pred), decimals=4)\n",
        "        precision_test=np.round(precision_score(data['y_test'], y_test_pred), decimals=4)\n",
        "        recall_test=np.round(recall_score(data['y_test'], y_test_pred), decimals=4)\n",
        "\n",
        "        resultsY[clf_name][data['name']] = (roc_train, precision_train, recall_train,\n",
        "                                           roc_test, precision_test, recall_test,\n",
        "                                           train_time, test_time)\n",
        "        df = pd.DataFrame(resultsY)\n",
        "        df.to_pickle('../results/numerical_temporary.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.DataFrame(resultsY)\n",
        "df.to_pickle('../results/numerical_y.pkl')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GRAPHS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from risf.distance_functions import DegreeDivergenceDist, JaccardDist\n",
        "from risf.risf_data import RisfData\n",
        "from data.data_getter import get_ucr_time_series, get_glocalkd_dataset\n",
        "from risf.forest import RandomIsolationSimilarityForest\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        }
      ],
      "source": [
        "clfs_names = [\"IForest\", \"ISF\", 'ECOD', 'LOF', 'HBOS', \"RISF\"]\n",
        "results = defaultdict(lambda : defaultdict(lambda: {}))\n",
        "\n",
        "#datasets_loop = tqdm(get_graphs(), desc=\"Datasets (outer loop)\", position=0)\n",
        "DATA_DIR = \"../data/graph\"\n",
        "datasets_loop = [\"NCI1\", \"REDDIT-BINARY\", \"PPAR-gamma\"]\n",
        "distances = np.array([\"JaccardDist\", \"DegreeDivergenceDist\"], dtype=object)\n",
        "algorithms_loop = tqdm(clfs_names, desc=\" Algorithms (inner loop)\", position=1, leave=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No node attributes\n",
            "train_counts (array([0, 1]), array([1437,  144], dtype=int64))\n",
            "test_counts (array([0, 1]), array([616, 617], dtype=int64))\n",
            "IForest, on NCI1 obtained, auc_train: 0.5751 and auc_test: 0.5874\n",
            "ISF, on NCI1 obtained, auc_train: 0.3856 and auc_test: 0.3691\n",
            "ECOD, on NCI1 obtained, auc_train: 0.5944 and auc_test: 0.5643\n",
            "LOF, on NCI1 obtained, auc_train: 0.5263 and auc_test: 0.54\n",
            "HBOS, on NCI1 obtained, auc_train: 0.5742 and auc_test: 0.5608\n",
            "Distances already calculated. Skipping...\n",
            "Distances already calculated. Skipping...\n",
            "Distances already calculated. Skipping...\n",
            "Distances already calculated. Skipping...\n",
            "RISF_Jac_Deg, on NCI1 obtained, auc_train: 0.5229 and auc_test: 0.4769\n",
            "Distances already calculated. Skipping...\n",
            "Distances already calculated. Skipping...\n",
            "RISF_Jac, on NCI1 obtained, auc_train: 0.4033 and auc_test: 0.3719\n",
            "Distances already calculated. Skipping...\n",
            "Distances already calculated. Skipping...\n",
            "RISF_Deg, on NCI1 obtained, auc_train: 0.5153 and auc_test: 0.4842\n",
            "No node labels\n",
            "No node attributes\n",
            "train_counts (array([0, 1]), array([700,  70], dtype=int64))\n",
            "test_counts (array([0, 1]), array([300, 300], dtype=int64))\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[9], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m distances_to_use \u001b[39m=\u001b[39m get_binary_distances_choice(distances)\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m dataset_name \u001b[39min\u001b[39;00m datasets_loop:\n\u001b[1;32m----> 4\u001b[0m     data \u001b[39m=\u001b[39m get_glocalkd_dataset(DATA_DIR, dataset_name)\n\u001b[0;32m      5\u001b[0m     \u001b[39mfor\u001b[39;00m clf_name \u001b[39min\u001b[39;00m algorithms_loop:\n\u001b[0;32m      6\u001b[0m         algorithms_loop\u001b[39m.\u001b[39mset_description(clf_name)\n",
            "File \u001b[1;32mD:\\AI_y3_s1\\ProblemClasses\\Isolation-Similarity-Forest\\data\\data_getter.py:207\u001b[0m, in \u001b[0;36mget_glocalkd_dataset\u001b[1;34m(data_dir, dataset_name)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrain_counts \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39munique(y_train, return_counts\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    203\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtest_counts \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39munique(y_test, return_counts\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    205\u001b[0m \u001b[39mreturn\u001b[39;00m {\n\u001b[0;32m    206\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mX_train\u001b[39m\u001b[39m\"\u001b[39m: X_train,\n\u001b[1;32m--> 207\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mX_train_num\u001b[39m\u001b[39m\"\u001b[39m: make_X_numeric(X_train, dataset_name),\n\u001b[0;32m    208\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39my_train\u001b[39m\u001b[39m\"\u001b[39m: y_train,\n\u001b[0;32m    209\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mX_test\u001b[39m\u001b[39m\"\u001b[39m: X_test,\n\u001b[0;32m    210\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mX_test_num\u001b[39m\u001b[39m\"\u001b[39m: make_X_numeric(X_test, dataset_name),\n\u001b[0;32m    211\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39my_test\u001b[39m\u001b[39m\"\u001b[39m: y_test,\n\u001b[0;32m    212\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: dataset_name\n\u001b[0;32m    213\u001b[0m }\n",
            "File \u001b[1;32mD:\\AI_y3_s1\\ProblemClasses\\Isolation-Similarity-Forest\\data\\data_getter.py:75\u001b[0m, in \u001b[0;36mmake_X_numeric\u001b[1;34m(X_graphs, dataset_name)\u001b[0m\n\u001b[0;32m     73\u001b[0m X_num \u001b[39m=\u001b[39m []\n\u001b[0;32m     74\u001b[0m \u001b[39mfor\u001b[39;00m graph \u001b[39min\u001b[39;00m X_graphs:\n\u001b[1;32m---> 75\u001b[0m     X_num\u001b[39m.\u001b[39mappend(graph_centrality_measures(graph, dataset_name))\n\u001b[0;32m     77\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(X_num)\n",
            "File \u001b[1;32mD:\\AI_y3_s1\\ProblemClasses\\Isolation-Similarity-Forest\\data\\data_getter.py:64\u001b[0m, in \u001b[0;36mgraph_centrality_measures\u001b[1;34m(graph, dataset_name)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m functions:\n\u001b[0;32m     63\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m         centralityMeasures\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39maverage(\u001b[39mlist\u001b[39m(f(graph)\u001b[39m.\u001b[39mvalues())))\n\u001b[0;32m     65\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m     66\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfailed to calculate \u001b[39m\u001b[39m{\u001b[39;00mf\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m inserting 0\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\sebas\\AppData\\pypoetry\\virtualenvs\\random-isolation-similarity-forest-bqxKmFq8-py3.10\\lib\\site-packages\\networkx\\algorithms\\centrality\\closeness.py:122\u001b[0m, in \u001b[0;36mcloseness_centrality\u001b[1;34m(G, u, distance, wf_improved)\u001b[0m\n\u001b[0;32m    120\u001b[0m closeness_dict \u001b[39m=\u001b[39m {}\n\u001b[0;32m    121\u001b[0m \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m nodes:\n\u001b[1;32m--> 122\u001b[0m     sp \u001b[39m=\u001b[39m path_length(G, n)\n\u001b[0;32m    123\u001b[0m     totsp \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(sp\u001b[39m.\u001b[39mvalues())\n\u001b[0;32m    124\u001b[0m     len_G \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(G)\n",
            "File \u001b[1;32mc:\\Users\\sebas\\AppData\\pypoetry\\virtualenvs\\random-isolation-similarity-forest-bqxKmFq8-py3.10\\lib\\site-packages\\networkx\\algorithms\\shortest_paths\\unweighted.py:59\u001b[0m, in \u001b[0;36msingle_source_shortest_path_length\u001b[1;34m(G, source, cutoff)\u001b[0m\n\u001b[0;32m     57\u001b[0m     cutoff \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39minf\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     58\u001b[0m nextlevel \u001b[39m=\u001b[39m {source: \u001b[39m1\u001b[39m}\n\u001b[1;32m---> 59\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mdict\u001b[39;49m(_single_shortest_path_length(G\u001b[39m.\u001b[39;49madj, nextlevel, cutoff))\n",
            "File \u001b[1;32mc:\\Users\\sebas\\AppData\\pypoetry\\virtualenvs\\random-isolation-similarity-forest-bqxKmFq8-py3.10\\lib\\site-packages\\networkx\\algorithms\\shortest_paths\\unweighted.py:91\u001b[0m, in \u001b[0;36m_single_shortest_path_length\u001b[1;34m(adj, firstlevel, cutoff)\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m     90\u001b[0m     \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m found:\n\u001b[1;32m---> 91\u001b[0m         nextlevel\u001b[39m.\u001b[39;49mupdate(adj[v])\n\u001b[0;32m     92\u001b[0m     level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     93\u001b[0m \u001b[39mdel\u001b[39;00m seen\n",
            "File \u001b[1;32mc:\\Users\\sebas\\AppData\\pypoetry\\virtualenvs\\random-isolation-similarity-forest-bqxKmFq8-py3.10\\lib\\site-packages\\networkx\\classes\\coreviews.py:50\u001b[0m, in \u001b[0;36mAtlasView.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__len__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     48\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_atlas)\n\u001b[1;32m---> 50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     51\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39miter\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_atlas)\n\u001b[0;32m     53\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key):\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1758\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.ThreadTracer.__call__\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\sebas\\AppData\\pypoetry\\virtualenvs\\random-isolation-similarity-forest-bqxKmFq8-py3.10\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\_pydev_bundle\\pydev_is_thread_alive.py:9\u001b[0m, in \u001b[0;36mis_thread_alive\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m      6\u001b[0m _temp \u001b[39m=\u001b[39m threading\u001b[39m.\u001b[39mThread()\n\u001b[0;32m      7\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(_temp, \u001b[39m'\u001b[39m\u001b[39m_is_stopped\u001b[39m\u001b[39m'\u001b[39m):  \u001b[39m# Python 3.x has this\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mis_thread_alive\u001b[39m(t):\n\u001b[0;32m     10\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mnot\u001b[39;00m t\u001b[39m.\u001b[39m_is_stopped\n\u001b[0;32m     12\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(_temp, \u001b[39m'\u001b[39m\u001b[39m_Thread__stopped\u001b[39m\u001b[39m'\u001b[39m):  \u001b[39m# Python 2.x has this\u001b[39;00m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "distances_to_use = get_binary_distances_choice(distances)\n",
        "\n",
        "for dataset_name in datasets_loop:\n",
        "    data = get_glocalkd_dataset(DATA_DIR, dataset_name)\n",
        "    for clf_name in algorithms_loop:\n",
        "        algorithms_loop.set_description(clf_name)\n",
        "    \n",
        "        if clf_name == \"RISF\":\n",
        "            for dist_to_use in distances_to_use:\n",
        "                dist = distances[dist_to_use]\n",
        "                train_risf(data, dataset_name, dist)\n",
        "        else:\n",
        "            clf = new_clf(clf_name, SEED)\n",
        "            clf.fit(data[\"X_train_num\"])\n",
        "            y_train_pred = clf.decision_function(data[\"X_train_num\"])\n",
        "            y_test_pred = clf.decision_function(data[\"X_test_num\"])\n",
        "            \n",
        "            add_scores(results, clf_name, data, y_train_pred, y_test_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "for split, result in results.items():\n",
        "    df = pd.DataFrame(result)\n",
        "    df.to_pickle(f'../results/{split}_graphs.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IForest</th>\n",
              "      <th>ISF</th>\n",
              "      <th>ECOD</th>\n",
              "      <th>LOF</th>\n",
              "      <th>HBOS</th>\n",
              "      <th>RISF_Jac_Deg</th>\n",
              "      <th>RISF_Jac</th>\n",
              "      <th>RISF_Deg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>NCI1</th>\n",
              "      <td>0.5947</td>\n",
              "      <td>0.3731</td>\n",
              "      <td>0.5639</td>\n",
              "      <td>0.5403</td>\n",
              "      <td>0.5562</td>\n",
              "      <td>0.4769</td>\n",
              "      <td>0.3719</td>\n",
              "      <td>0.4842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>REDDIT-BINARY</th>\n",
              "      <td>0.7050</td>\n",
              "      <td>0.1940</td>\n",
              "      <td>0.6375</td>\n",
              "      <td>0.6232</td>\n",
              "      <td>0.5127</td>\n",
              "      <td>0.5632</td>\n",
              "      <td>0.4132</td>\n",
              "      <td>0.5705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PPAR-gamma</th>\n",
              "      <td>0.5804</td>\n",
              "      <td>0.2866</td>\n",
              "      <td>0.5942</td>\n",
              "      <td>0.4368</td>\n",
              "      <td>0.5792</td>\n",
              "      <td>0.5204</td>\n",
              "      <td>0.4124</td>\n",
              "      <td>0.5522</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               IForest     ISF    ECOD     LOF    HBOS  RISF_Jac_Deg  \\\n",
              "NCI1            0.5947  0.3731  0.5639  0.5403  0.5562        0.4769   \n",
              "REDDIT-BINARY   0.7050  0.1940  0.6375  0.6232  0.5127        0.5632   \n",
              "PPAR-gamma      0.5804  0.2866  0.5942  0.4368  0.5792        0.5204   \n",
              "\n",
              "               RISF_Jac  RISF_Deg  \n",
              "NCI1             0.3719    0.4842  \n",
              "REDDIT-BINARY    0.4132    0.5705  \n",
              "PPAR-gamma       0.4124    0.5522  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#TEST\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IForest</th>\n",
              "      <th>ISF</th>\n",
              "      <th>ECOD</th>\n",
              "      <th>LOF</th>\n",
              "      <th>HBOS</th>\n",
              "      <th>RISF_Jac_Deg</th>\n",
              "      <th>RISF_Jac</th>\n",
              "      <th>RISF_Deg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>NCI1</th>\n",
              "      <td>0.5825</td>\n",
              "      <td>0.3873</td>\n",
              "      <td>0.5948</td>\n",
              "      <td>0.5276</td>\n",
              "      <td>0.5672</td>\n",
              "      <td>0.5229</td>\n",
              "      <td>0.4033</td>\n",
              "      <td>0.5153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>REDDIT-BINARY</th>\n",
              "      <td>0.7143</td>\n",
              "      <td>0.2277</td>\n",
              "      <td>0.7075</td>\n",
              "      <td>0.6189</td>\n",
              "      <td>0.5132</td>\n",
              "      <td>0.5807</td>\n",
              "      <td>0.4170</td>\n",
              "      <td>0.5904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PPAR-gamma</th>\n",
              "      <td>0.4775</td>\n",
              "      <td>0.4139</td>\n",
              "      <td>0.5258</td>\n",
              "      <td>0.4795</td>\n",
              "      <td>0.4936</td>\n",
              "      <td>0.4402</td>\n",
              "      <td>0.4282</td>\n",
              "      <td>0.4445</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               IForest     ISF    ECOD     LOF    HBOS  RISF_Jac_Deg  \\\n",
              "NCI1            0.5825  0.3873  0.5948  0.5276  0.5672        0.5229   \n",
              "REDDIT-BINARY   0.7143  0.2277  0.7075  0.6189  0.5132        0.5807   \n",
              "PPAR-gamma      0.4775  0.4139  0.5258  0.4795  0.4936        0.4402   \n",
              "\n",
              "               RISF_Jac  RISF_Deg  \n",
              "NCI1             0.4033    0.5153  \n",
              "REDDIT-BINARY    0.4170    0.5904  \n",
              "PPAR-gamma       0.4282    0.4445  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#TRAIN\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Datasets (outer loop): 0it [00:00, ?it/s]"
          ]
        }
      ],
      "source": [
        "clfs_names = [\"IForest\", \"ISF\", 'ECOD', 'LOF', 'HBOS', \"RISF\"]\n",
        "results = {x: {} for x in clfs_names}\n",
        "\n",
        "datasets_loop = tqdm(get_ucr_time_series(), desc=\"Datasets (outer loop)\", position=0)\n",
        "algorithms_loop = tqdm(clfs_names, desc=\" Algorithms (inner loop)\", position=1, leave=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from fastdtw import fastdtw\n",
        "\n",
        "def dtw(series1, series2):\n",
        "     return fastdtw(series1, series2)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computers: : 0it [00:00, ?it/s]          "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IForest, on Computers obtained, auc_train: 0.352 and auc_test: 0.3747\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ISF, on Computers obtained, auc_train: 0.6 and auc_test: 0.448\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ECOD, on Computers obtained, auc_train: 0.372 and auc_test: 0.3467\n",
            "LOF, on Computers obtained, auc_train: 0.556 and auc_test: 0.588\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HBOS, on Computers obtained, auc_train: 0.4093 and auc_test: 0.2947\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "HouseTwenty: : 1it [05:20, 320.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RISF, on Computers obtained, auc_train: 0.3187 and auc_test: 0.296\n",
            "IForest, on HouseTwenty obtained, auc_train: 1.0 and auc_test: 0.8841\n",
            "ISF, on HouseTwenty obtained, auc_train: 0.75 and auc_test: 0.087\n",
            "ECOD, on HouseTwenty obtained, auc_train: 1.0 and auc_test: 0.5604\n",
            "LOF, on HouseTwenty obtained, auc_train: 0.85 and auc_test: 0.2053\n",
            "HBOS, on HouseTwenty obtained, auc_train: 0.8 and auc_test: 0.9758\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "HouseTwenty: : 2it [06:33, 196.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RISF, on HouseTwenty obtained, auc_train: 0.85 and auc_test: 0.7778\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "high <= 0",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m datasets_loop:\n\u001b[0;32m      2\u001b[0m     datasets_loop\u001b[39m.\u001b[39mset_description(data[\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m     \u001b[39mfor\u001b[39;00m clf_name \u001b[39min\u001b[39;00m algorithms_loop:\n",
            "File \u001b[1;32mc:\\Users\\sebas\\AppData\\pypoetry\\virtualenvs\\random-isolation-similarity-forest-bqxKmFq8-py3.10\\lib\\site-packages\\tqdm\\std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
            "File \u001b[1;32md:\\AI_y3_s1\\ProblemClasses\\Isolation-Similarity-Forest\\notebooks\\..\\data\\data_getter.py:150\u001b[0m, in \u001b[0;36mget_ucr_time_series\u001b[1;34m(wanted_datasets)\u001b[0m\n\u001b[0;32m    148\u001b[0m y_train[y_train \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    149\u001b[0m y_train[y_train \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 150\u001b[0m X_train, y_train \u001b[39m=\u001b[39m downsample(X_train, y_train, OUTLIERS_RATIO)\n\u001b[0;32m    152\u001b[0m X_test \u001b[39m=\u001b[39m df_test\u001b[39m.\u001b[39miloc[:, \u001b[39m1\u001b[39m:]\u001b[39m.\u001b[39mto_numpy()\n\u001b[0;32m    153\u001b[0m y_test \u001b[39m=\u001b[39m df_test\u001b[39m.\u001b[39miloc[:, \u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto_numpy()\n",
            "File \u001b[1;32md:\\AI_y3_s1\\ProblemClasses\\Isolation-Similarity-Forest\\notebooks\\..\\data\\data_getter.py:28\u001b[0m, in \u001b[0;36mdownsample\u001b[1;34m(X, y, p)\u001b[0m\n\u001b[0;32m     25\u001b[0m outs_indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(y \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[0;32m     26\u001b[0m n_outs_samples \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m(\u001b[39mlen\u001b[39m(ins_indices) \u001b[39m*\u001b[39m p)\n\u001b[1;32m---> 28\u001b[0m outs_indices_subset \u001b[39m=\u001b[39m resample(outs_indices, n_samples\u001b[39m=\u001b[39;49mn_outs_samples, random_state\u001b[39m=\u001b[39;49m\u001b[39m23\u001b[39;49m)\n\u001b[0;32m     29\u001b[0m undersampled_indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate([ins_indices, outs_indices_subset])\n\u001b[0;32m     31\u001b[0m X_undersampled \u001b[39m=\u001b[39m X[undersampled_indices]\n",
            "File \u001b[1;32mc:\\Users\\sebas\\AppData\\pypoetry\\virtualenvs\\random-isolation-similarity-forest-bqxKmFq8-py3.10\\lib\\site-packages\\sklearn\\utils\\__init__.py:573\u001b[0m, in \u001b[0;36mresample\u001b[1;34m(replace, n_samples, random_state, stratify, *arrays)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[39mif\u001b[39;00m stratify \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    572\u001b[0m     \u001b[39mif\u001b[39;00m replace:\n\u001b[1;32m--> 573\u001b[0m         indices \u001b[39m=\u001b[39m random_state\u001b[39m.\u001b[39;49mrandint(\u001b[39m0\u001b[39;49m, n_samples, size\u001b[39m=\u001b[39;49m(max_n_samples,))\n\u001b[0;32m    574\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    575\u001b[0m         indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(n_samples)\n",
            "File \u001b[1;32mmtrand.pyx:746\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32m_bounded_integers.pyx:1338\u001b[0m, in \u001b[0;36mnumpy.random._bounded_integers._rand_int32\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: high <= 0"
          ]
        }
      ],
      "source": [
        "for data in datasets_loop:\n",
        "    datasets_loop.set_description(data['name'])\n",
        "    for clf_name in algorithms_loop:\n",
        "        algorithms_loop.set_description(clf_name)\n",
        "        clf = new_clf(clf_name, SEED)\n",
        "\n",
        "        if clf_name == \"RISF\":\n",
        "            X_risf = RisfData()\n",
        "            X_risf.add_data(data[\"X_train\"], dist = dtw)\n",
        "            X_risf.precompute_distances(n_jobs=-2)\n",
        "            clf = RandomIsolationSimilarityForest(random_state=SEED, distance=X_risf.distances, n_jobs=-3).fit(X_risf)\n",
        "            y_train_pred = (-1)*clf.predict(X_risf, return_raw_scores=True)\n",
        "\n",
        "            X_test_risf = clf.transform([data[\"X_test\"]], n_jobs=-2)\n",
        "            y_test_pred = (-1)*clf.predict(X_test_risf, return_raw_scores=True)\n",
        "            \n",
        "        else:\n",
        "            clf.fit(data[\"X_train\"])\n",
        "            if clf_name == \"ISF\":\n",
        "                y_train_pred = clf.score_samples(data[\"X_train\"])\n",
        "                y_test_pred = clf.score_samples(data[\"X_test\"])\n",
        "            else:\n",
        "                y_train_pred = clf.decision_function(data[\"X_train\"])\n",
        "                y_test_pred = clf.decision_function(data[\"X_test\"])\n",
        "        \n",
        "        auc_train = calculate_stats(data[\"y_train\"], y_train_pred)\n",
        "        auc_test = calculate_stats(data[\"y_test\"], y_test_pred)\n",
        "\n",
        "        results[clf_name][data['name']] = (auc_train, auc_test)\n",
        "\n",
        "        print(f\"{clf_name}, on {data['name']} obtained, auc_train: {auc_train} and auc_test: {auc_test}\")\n",
        "    \n",
        "    df = pd.DataFrame(results)\n",
        "    df.to_pickle('../results/time_series.pkl')\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.0 ('.venv': poetry)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "2b56e3c97de72a7673ee0fcfb94642a98e5ba521673e7fa53275c57ef5fa8664"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
